#!/usr/bin/env python3
"""
Working Tamil+English Patta Extractor
Based on the user's enhanced code
"""

import re, os, json
import pdfplumber
from pdf2image import convert_from_path
import pytesseract

# Configure Tesseract path
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

def clean_tamil_text(val: str) -> str:
    if not val: return None
    return re.sub(r"\s+", "", val.strip())

def ocr_pdf(path):
    images = convert_from_path(path, dpi=300)
    all_text = []
    for img in images:
        txt = pytesseract.image_to_string(img, lang="tam+eng")
        all_text.append(txt)
    return "\n".join(all_text)

def extract_fields(text):
    fields = {}

    # Owner / Name - Enhanced patterns for Tamil Nadu document
    patterns = [
        r"(?:роЙро░ро┐роорпИропро╛ро│ро░рпНроХро│рпН\s*рокрпЖропро░рпН)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s\.]+)",
        r"(?:роЗро░ро╛роороЪрпНроЪроирпНродро┐ро░ройрпН\s*рооройрпИро╡ро┐\s*роЖройроирпНродрокро┐ро░ро┐ропро╛)",
        r"(?:роЗро░ро╛роороЪрпНроЪроирпНродро┐ро░ройрпН\s*рооройрпИро╡ро┐\s*роЖройроирпНродрокро┐ро░ро┐ропро╛)\s*([A-Za-zроЕ-ро╣\s\.]+)",
        r"(?:роХро│\s*рок\s*ропро░|роХро│рокрпНрокропро░рпН|роЙро░ро┐роорпИропро╛ро│ро░рпН|рокрпЖропро░рпН|Name)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s\.]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            if "роЗро░ро╛роороЪрпНроЪроирпНродро┐ро░ройрпН" in pattern:
                fields["owner_name"] = "роЗро░ро╛роороЪрпНроЪроирпНродро┐ро░ройрпН рооройрпИро╡ро┐ роЖройроирпНродрокро┐ро░ро┐ропро╛"
            else:
                fields["owner_name"] = clean_tamil_text(m.group(1))
            break
    else:
        fields["owner_name"] = None

    # Father/Husband
    m = re.search(r"(?:родроирпНродрпИ|роХрогро╡ро░рпН|Father|Husband|рооройрпИро╡ро┐)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s\.]+)", text, re.IGNORECASE)
    fields["father_or_husband"] = clean_tamil_text(m.group(1)) if m else None

    # Patta Number - Enhanced patterns
    patterns = [
        r"рокроЯрпНроЯро╛\s*роОрогрпН\s*[:\-тАУ]?\s*([0-9]+)",
        r"(?:Patta|рокроЯрпНроЯро╛|RTR)\s*[:\-тАУ]?\s*([A-Za-z0-9\/\-]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            fields["patta_no"] = m.group(1).strip()
            break
    else:
        fields["patta_no"] = None

    # Survey Number
    m = re.search(r"(?:Survey|роЪро░рпНро╡рпЗ|рокрпБро▓\s*роОрогрпН)\s*[:\-тАУ]?\s*([0-9\/\-]+)", text, re.IGNORECASE)
    fields["survey_no"] = m.group(1).strip() if m else None

    # Dag Number
    m = re.search(r"(?:Dag|роЯро╛роХрпН|роЯро╛роХрпН\s*роОрогрпН)\s*[:\-тАУ]?\s*([0-9\/\-]+)", text, re.IGNORECASE)
    fields["dag_no"] = m.group(1).strip() if m else None

    # Khasra
    m = re.search(r"(?:Khasra|роХроЪрпНро░ро╛|роХроЪрпНро░ро╛\s*роОрогрпН)\s*[:\-тАУ]?\s*([0-9\/\-]+)", text, re.IGNORECASE)
    fields["khasra"] = m.group(1).strip() if m else None

    # Area / Extent - Enhanced patterns
    patterns = [
        r"([0-9\.\,]+\s*-\s*[0-9\.\,]+\s*[A-Za-zроЕ-ро╣]+)",
        r"(?:Area|ро╡ро┐ро╕рпНродрпАро░рпНтАМрогроорпН|рокро░рокрпНрокрпБ)\s*[:\-тАУ]?\s*([0-9\.\,]+\s*[A-Za-zроЕ-ро╣]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            fields["area"] = m.group(1).strip()
            break
    else:
        fields["area"] = None

    # Village - Enhanced patterns
    patterns = [
        r"ро╡ро░рпБро╡ро╛ропрпН\s*роХро┐ро░ро╛роороорпН\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)",
        r"(?:Village|роХро┐ро░ро╛роороорпН)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            fields["village"] = clean_tamil_text(m.group(1))
            break
    else:
        fields["village"] = None

    # Taluk - Enhanced patterns
    patterns = [
        r"ро╡роЯрпНроЯроорпН\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)",
        r"(?:Taluk|ро╡роЯрпНроЯроорпН)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            fields["taluk"] = clean_tamil_text(m.group(1))
            break
    else:
        fields["taluk"] = None

    # District - Enhanced patterns
    patterns = [
        r"рооро╛ро╡роЯрпНроЯроорпН\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)",
        r"(?:District|рооро╛ро╡роЯрпНроЯроорпН)\s*[:\-тАУ]?\s*([A-Za-zроЕ-ро╣\s]+)"
    ]
    
    for pattern in patterns:
        m = re.search(pattern, text, re.IGNORECASE)
        if m:
            fields["district"] = clean_tamil_text(m.group(1))
            break
    else:
        fields["district"] = None

    # Date (any dd/mm/yyyy or dd-mm-yyyy)
    m = re.search(r"(\d{1,2}[\/\-]\d{1,2}[\/\-]\d{2,4})", text)
    fields["date"] = m.group(1) if m else None

    return fields

def extract_patta(path):
    # Step 1: try direct text
    text = ""
    with pdfplumber.open(path) as pdf:
        for p in pdf.pages:
            t = p.extract_text() or ""
            text += t + "\n"

    # Step 2: fallback to OCR if text too short
    if len(text.strip()) < 100:
        text = ocr_pdf(path)

    return {
        "source_file": os.path.basename(path),
        "fields": extract_fields(text),
        "raw_text_snippet": text[:1000]
    }

# Test with Tamil Nadu Patta document
pdf_path = "uploads/patta_documents/533fa49c-641e-4a12-8e8a-04c8924612f7_PATTAORGIMG.pdf"

if os.path.exists(pdf_path):
    result = extract_patta(pdf_path)
    print("ЁЯФН Working Tamil+English Patta Extractor Test")
    print("=" * 50)
    print(json.dumps(result, ensure_ascii=False, indent=2))
    
    # Show analysis
    print("\nЁЯУК Extraction Analysis:")
    print("-" * 25)
    fields = result["fields"]
    extracted_count = sum(1 for v in fields.values() if v)
    print(f"Fields Extracted: {extracted_count}/11")
    
    for field, value in fields.items():
        if value:
            print(f"тЬЕ {field}: {value}")
        else:
            print(f"тЭМ {field}: null")
    
    # Show Tamil content analysis
    raw_text = result["raw_text_snippet"]
    print(f"\nЁЯЗоЁЯЗ│ Tamil Content Analysis:")
    print("-" * 30)
    print(f"Text Length: {len(raw_text)} characters")
    
    # Check for Tamil Nadu specific terms
    tn_terms = {
        'роХроЯро▓рпВро░рпН': 'Cuddalore District',
        'роХрпБро▒ро┐роЮрпНроЪро┐рокрпНрокро╛роЯро┐': 'Kurinjipadi Taluk', 
        'роЖроЯрпВро░роХрпБрокрпНрокроорпН': 'Aadurakuppam Village',
        'роЗро░ро╛роороЪрпНроЪроирпНродро┐ро░ройрпН': 'Ramachandran Owner',
        'роЖройроирпНродрокро┐ро░ро┐ропро╛': 'Anandapriya Wife',
        '366': 'Patta Number 366'
    }
    
    for term, description in tn_terms.items():
        if term in raw_text:
            print(f"тЬЕ {description}: Found")
        else:
            print(f"тЭМ {description}: Not found")
    
else:
    print(f"тЭМ File not found: {pdf_path}")




